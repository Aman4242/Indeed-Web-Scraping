{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc47b145-8084-4ba2-ab78-4576229c0388",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching page 1...\n",
      "✅ Scraped 15 jobs so far.\n",
      "Fetching page 2...\n",
      "✅ Scraped 30 jobs so far.\n",
      "Fetching page 3...\n",
      "✅ Scraped 45 jobs so far.\n",
      "Fetching page 4...\n",
      "✅ Scraped 52 jobs so far.\n",
      "Fetching page 5...\n",
      "✅ Scraped 67 jobs so far.\n",
      "Fetching page 6...\n",
      "✅ Scraped 82 jobs so far.\n",
      "✅ Job data saved to 'indeed_jobs_updated.csv'\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "def get_driver():\n",
    "    options = Options()\n",
    "    options.add_argument(\"--start-maximized\")  # Ensure browser is maximized\n",
    "    options.add_argument(\"--disable-blink-features=AutomationControlled\")  # Prevent bot detection\n",
    "    options.add_argument(\"--disable-popup-blocking\")  \n",
    "    options.add_argument(\"--disable-notifications\")\n",
    "    service = Service(ChromeDriverManager().install())\n",
    "    driver = webdriver.Chrome(service=service, options=options)\n",
    "    return driver\n",
    "\n",
    "def scrape_indeed_jobs(job_title, search_location, num_pages=3):\n",
    "    driver = get_driver()\n",
    "    base_url = \"https://in.indeed.com/jobs?q={}&l={}&start={}\"\n",
    "    job_data = []\n",
    "    \n",
    "    for page in range(num_pages):\n",
    "        print(f\"Fetching page {page + 1}...\")\n",
    "        url = base_url.format(job_title.replace(\" \", \"+\"), search_location.replace(\" \", \"+\"), page * 10)\n",
    "        driver.get(url)\n",
    "        \n",
    "        time.sleep(5)  # Allow page to load\n",
    "        \n",
    "        job_cards = driver.find_elements(By.CSS_SELECTOR, \"div.job_seen_beacon\")\n",
    "        for job in job_cards:\n",
    "            try:\n",
    "                title = job.find_element(By.CSS_SELECTOR, \"h2.jobTitle\").text.strip()\n",
    "            except:\n",
    "                title = \"N/A\"\n",
    "            \n",
    "            try:\n",
    "                company_location = job.find_element(By.CSS_SELECTOR, \"div.company_location\").text.strip()\n",
    "                split_data = company_location.split(\"\\n\")\n",
    "                company = split_data[0].strip() if len(split_data) > 1 else \"N/A\"\n",
    "                job_location = split_data[1].strip() if len(split_data) > 1 else split_data[0]\n",
    "            except:\n",
    "                company, job_location = \"N/A\", \"N/A\"\n",
    "\n",
    "            try:\n",
    "                salary = job.find_element(By.CSS_SELECTOR, \"div.metadata.salary-snippet-container\").text.strip()\n",
    "            except:\n",
    "                salary = \"Unpaid\"\n",
    "\n",
    "            try:\n",
    "                job_link_element = job.find_element(By.CSS_SELECTOR, \"a\")\n",
    "                partial_url = job_link_element.get_attribute(\"href\")\n",
    "                job_link = partial_url if partial_url.startswith(\"http\") else f\"https://in.indeed.com{partial_url}\"\n",
    "            except:\n",
    "                job_link = \"N/A\"\n",
    "\n",
    "            job_data.append({\n",
    "                \"Title\": title,\n",
    "                \"Company\": company,\n",
    "                \"Job Location\": job_location,\n",
    "                \"Salary\": salary,\n",
    "                \"Link\": job_link\n",
    "            })\n",
    "        \n",
    "        print(f\"✅ Scraped {len(job_data)} jobs so far.\")\n",
    "    \n",
    "    driver.quit()\n",
    "    \n",
    "    # Saving Data to CSV\n",
    "    df = pd.DataFrame(job_data)\n",
    "    df.to_csv(\"indeed_jobs.csv\", index=False)\n",
    "    print(\"✅ Job data saved to 'indeed_jobs_updated.csv'\")\n",
    "\n",
    "# Example usage\n",
    "scrape_indeed_jobs(\"Data Scientist\", \"New Delhi, Delhi\", num_pages=6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd98765a-481a-403b-ba62-fe9106074a7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
